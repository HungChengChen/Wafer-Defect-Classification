{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "\n",
    "from lightning.lite.utilities.seed import seed_everything\n",
    "\n",
    "\n",
    "class opts(object):\n",
    "    def __init__(self):\n",
    "        self.opt = None\n",
    "        self.parser = argparse.ArgumentParser()\n",
    "        self.parser.add_argument(\n",
    "            \"--exp_id\", type=str, default=\"default\", help=\"Name of the project.\"\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--class_mode\",\n",
    "            type=str,\n",
    "            default=\"binary\",\n",
    "            choices=[\"binary\", \"multiclass\"],\n",
    "            help=\"Choose between 'binary' or 'multiclass' classification.\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--sampling\",\n",
    "            type=str,\n",
    "            default=\"kfold\",\n",
    "            choices=[\"kfold\", \"stratified\"],\n",
    "            help=\"Choose between 'kfold' or 'stratified' sampling.\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--n_splits\",\n",
    "            type=int,\n",
    "            default=5,\n",
    "            help=\"For 'kfold' sampling, it represents the number of folds. For 'stratified' sampling, \\\n",
    "            it represents the percentage of the dataset to include in the validation split (1/n_splits).\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--data_dir\",\n",
    "            type=str,\n",
    "            default=\"data/Binary\",\n",
    "            help=\"Directory containing the data\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--model_name\",\n",
    "            type=str,\n",
    "            default=\"convnext_tiny.fb_in1k\",\n",
    "            help=\"Name of the model to use (see torchvision.models for options)\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--use_pretrained\",\n",
    "            type=bool,\n",
    "            default=True,\n",
    "            help=\"Whether to use pretrained weights.\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--devices\",\n",
    "            type=str,\n",
    "            default=\"auto\",\n",
    "            help=\"The devices to use (e.g., '1' for one GPU, '[0,1,2]' for GPUs 0, 1, and 2, 'auto' for all available GPUs).\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--accelerator\",\n",
    "            type=str,\n",
    "            default=\"cuda\",\n",
    "            help=\"Set the accelerator type ('cpu', 'gpu', 'tpu', 'ipu', 'hpu', 'mps', 'auto')\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--epochs\", type=int, default=60, help=\"Number of epochs to train for\"\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--lr\", type=float, default=1e-4, help=\"Learning rate for the optimizer\"\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--eta_min\",\n",
    "            type=float,\n",
    "            default=1e-5,\n",
    "            help=\"Minimum learning rate for the Cosine Annealing scheduler.\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--seed\",\n",
    "            type=int,\n",
    "            default=None,\n",
    "            help=\"Random state for reproducibility (use a specific seed or leave as None for a random seed)\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--min_batch_size\",\n",
    "            type=int,\n",
    "            default=32,\n",
    "            help=\"Batch size for training and validation\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--batch_size\", type=int, default=256, help=\"Batch size for testing\"\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--num_workers\",\n",
    "            type=int,\n",
    "            default=4,\n",
    "            help=\"Number of workers for data loading\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--gradient_clip_val\",\n",
    "            type=float,\n",
    "            default=0.5,\n",
    "            help=\"Gradient clipping value for the optimizer\",\n",
    "        )\n",
    "\n",
    "    def parse(self, args=\"\"):\n",
    "        self.opt = self.parser.parse_args(args if args else [])\n",
    "\n",
    "        self.opt.log_dir = f\"{self.opt.exp_id}/{self.opt.class_mode}_{self.opt.sampling}/{self.opt.model_name}\"\n",
    "\n",
    "        if self.opt.seed is None:\n",
    "            self.opt.seed = seed_everything()\n",
    "        else:\n",
    "            seed_everything(self.opt.seed)\n",
    "\n",
    "        # 解析設備參數\n",
    "        if self.opt.devices.isdigit():  # 如果是一個數字，指定使用該數量的GPU\n",
    "            num_gpus = int(self.opt.devices)\n",
    "            devices = num_gpus if num_gpus > 0 else \"auto\"\n",
    "        elif self.opt.devices in [\"auto\", \"-1\"]:  # 使用所有可用的GPU\n",
    "            devices = \"auto\"\n",
    "        else:\n",
    "            devices = [int(d) for d in re.findall(r\"\\d+\", self.opt.devices)]\n",
    "        self.opt.devices = devices\n",
    "        return self.opt\n",
    "\n",
    "    def set_fold(self, opt, fold_index):\n",
    "        opt.fold = fold_index\n",
    "        # opt.log_dir = f\"{opt.exp_id}/{opt.class_mode}_{opt.kfold}/{opt.seed}/{opt.model_name}/fold-{opt.fold}\"\n",
    "        opt.log_dir = os.path.join(opt.log_dir, f\"fold-{opt.fold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "from datasets.folder import ImageFolder\n",
    "from datasets.datamodule import DataModule\n",
    "from datasets.transforms import AUGMENTATION_TRANSFORMS, BASIC_TRANSFORMS\n",
    "from models.binary_moudle import BinaryModule\n",
    "from models.multiclass_moudle import MulticlassModule\n",
    "from trainers.base import create_trainer\n",
    "# from opts import opts\n",
    "\n",
    "args = opts().parse(\n",
    "    args=[\"--class_mode\", \"multiclass\", \"--sampling\", \"stratified\", \"--devices\", \"2\",\"--min_batch_size\", \"8\"]\n",
    ")\n",
    "\n",
    "train_dataset = ImageFolder(\n",
    "    root=args.data_dir,\n",
    "    transform=AUGMENTATION_TRANSFORMS(\n",
    "        img_size=[224, 224], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    ")\n",
    "val_dataset = ImageFolder(\n",
    "    root=args.data_dir,\n",
    "    transform=BASIC_TRANSFORMS(\n",
    "        img_size=[224, 224], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    ")\n",
    "datamodule = DataModule(\n",
    "    args, train_dataset=train_dataset, val_dataset=val_dataset\n",
    ")\n",
    "if args.sampling == \"kfold\":\n",
    "    for fold in range(args.n_splits):\n",
    "        opts().set_fold(args, fold_index=fold)\n",
    "        trainer = create_trainer(args)\n",
    "        if args.class_mode == \"binary\":\n",
    "            model = BinaryModule(args)\n",
    "        elif args.class_mode == \"multiclass\":\n",
    "            model = MulticlassModule(args)\n",
    "        trainer.fit(model, datamodule=datamodule)\n",
    "        \n",
    "elif args.sampling == \"stratified\":\n",
    "    trainer = create_trainer(args)\n",
    "    if args.class_mode == \"binary\":\n",
    "        model = BinaryModule(args)\n",
    "    elif args.class_mode == \"multiclass\":\n",
    "        model = MulticlassModule(args)\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc",
   "language": "python",
   "name": "sc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
