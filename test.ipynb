{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "\n",
    "from lightning.lite.utilities.seed import seed_everything\n",
    "\n",
    "\n",
    "class opts(object):\n",
    "    def __init__(self):\n",
    "        self.opt = None\n",
    "        self.parser = argparse.ArgumentParser()\n",
    "        self.parser.add_argument(\n",
    "            \"--exp_id\", type=str, default=\"default\", help=\"Name of the project.\"\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--class_mode\",\n",
    "            type=str,\n",
    "            default=\"binary\",\n",
    "            choices=[\"binary\", \"multiclass\"],\n",
    "            help=\"Choose between 'binary' or 'multiclass' classification.\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--sampling\",\n",
    "            type=str,\n",
    "            default=\"kfold\",\n",
    "            choices=[\"kfold\", \"stratified\"],\n",
    "            help=\"Choose between 'kfold' or 'stratified' sampling.\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--n_splits\",\n",
    "            type=int,\n",
    "            default=5,\n",
    "            help=\"For 'kfold' sampling, it represents the number of folds. For 'stratified' sampling, \\\n",
    "            it represents the percentage of the dataset to include in the validation split (1/n_splits).\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--data_dir\",\n",
    "            type=str,\n",
    "            default=\"data/Binary\",\n",
    "            help=\"Directory containing the data\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--model_name\",\n",
    "            type=str,\n",
    "            default=\"convnext_tiny.fb_in1k\",\n",
    "            help=\"Name of the model to use (see torchvision.models for options)\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--use_pretrained\",\n",
    "            type=bool,\n",
    "            default=True,\n",
    "            help=\"Whether to use pretrained weights.\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--devices\",\n",
    "            type=str,\n",
    "            default=\"auto\",\n",
    "            help=\"The devices to use (e.g., '1' for one GPU, '[0,1,2]' for GPUs 0, 1, and 2, 'auto' for all available GPUs).\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--accelerator\",\n",
    "            type=str,\n",
    "            default=\"cuda\",\n",
    "            help=\"Set the accelerator type ('cpu', 'gpu', 'tpu', 'ipu', 'hpu', 'mps', 'auto')\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--epochs\", type=int, default=60, help=\"Number of epochs to train for\"\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--lr\", type=float, default=1e-4, help=\"Learning rate for the optimizer\"\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--eta_min\",\n",
    "            type=float,\n",
    "            default=1e-5,\n",
    "            help=\"Minimum learning rate for the Cosine Annealing scheduler.\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--seed\",\n",
    "            type=int,\n",
    "            default=None,\n",
    "            help=\"Random state for reproducibility (use a specific seed or leave as None for a random seed)\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--min_batch_size\",\n",
    "            type=int,\n",
    "            default=32,\n",
    "            help=\"Batch size for training and validation\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--batch_size\", type=int, default=256, help=\"Batch size for testing\"\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--num_workers\",\n",
    "            type=int,\n",
    "            default=4,\n",
    "            help=\"Number of workers for data loading\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--gradient_clip_val\",\n",
    "            type=float,\n",
    "            default=0.5,\n",
    "            help=\"Gradient clipping value for the optimizer\",\n",
    "        )\n",
    "\n",
    "    def parse(self, args=\"\"):\n",
    "        self.opt = self.parser.parse_args(args if args else [])\n",
    "\n",
    "        self.opt.log_dir = f\"{self.opt.exp_id}/{self.opt.class_mode}_{self.opt.sampling}/{self.opt.model_name}\"\n",
    "\n",
    "        if self.opt.seed is None:\n",
    "            self.opt.seed = seed_everything()\n",
    "        else:\n",
    "            seed_everything(self.opt.seed)\n",
    "\n",
    "        # 解析設備參數\n",
    "        if self.opt.devices.isdigit():  # 如果是一個數字，指定使用該數量的GPU\n",
    "            num_gpus = int(self.opt.devices)\n",
    "            devices = num_gpus if num_gpus > 0 else \"auto\"\n",
    "        elif self.opt.devices in [\"auto\", \"-1\"]:  # 使用所有可用的GPU\n",
    "            devices = \"auto\"\n",
    "        else:\n",
    "            devices = [int(d) for d in re.findall(r\"\\d+\", self.opt.devices)]\n",
    "        self.opt.devices = devices\n",
    "        return self.opt\n",
    "\n",
    "    def set_fold(self, opt, fold_index):\n",
    "        opt.fold = fold_index\n",
    "        # opt.log_dir = f\"{opt.exp_id}/{opt.class_mode}_{opt.kfold}/{opt.seed}/{opt.model_name}/fold-{opt.fold}\"\n",
    "        opt.log_dir = os.path.join(opt.log_dir, f\"fold-{opt.fold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1544394114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 classes in 'data/Multiclass': OK, Pattern(1), Pattern(2), Pattern(3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No pretrained weights available for 'convnext_base'. Consider these pretrained options: ['convnext_base.clip_laion2b', 'convnext_base.clip_laion2b_augreg', 'convnext_base.clip_laion2b_augreg_ft_in1k', 'convnext_base.clip_laion2b_augreg_ft_in12k', 'convnext_base.clip_laion2b_augreg_ft_in12k_in1k', 'convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384', 'convnext_base.clip_laiona', 'convnext_base.clip_laiona_320', 'convnext_base.clip_laiona_augreg_320', 'convnext_base.clip_laiona_augreg_ft_in1k_384', 'convnext_base.fb_in1k', 'convnext_base.fb_in22k', 'convnext_base.fb_in22k_ft_in1k', 'convnext_base.fb_in22k_ft_in1k_384']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m ImageFolder(\n\u001b[1;32m     10\u001b[0m     root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/Multiclass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     transform\u001b[38;5;241m=\u001b[39mAUGMENTATION_TRANSFORMS(\n\u001b[1;32m     12\u001b[0m         img_size\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m], mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m]\n\u001b[1;32m     13\u001b[0m     ),\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m DataModule(args, train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset)\n\u001b[0;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMulticlassModule\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 創建輸入數據\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/models/multiclass_moudle.py:26\u001b[0m, in \u001b[0;36mMulticlassModule.__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx_to_class \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39midx_to_class\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Create the model; raise error if not binary classification\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_timm_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_pretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_pretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Loss function\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "File \u001b[0;32m~/models/model_factory.py:27\u001b[0m, in \u001b[0;36mcreate_timm_model\u001b[0;34m(model_name, num_classes, use_pretrained, in_chans)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m available_pretrained_models:\n\u001b[1;32m     26\u001b[0m         related_pretrained \u001b[38;5;241m=\u001b[39m timm\u001b[38;5;241m.\u001b[39mlist_models(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo pretrained weights available for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider these pretrained options: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelated_pretrained\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m         )\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing pretrained model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: No pretrained weights available for 'convnext_base'. Consider these pretrained options: ['convnext_base.clip_laion2b', 'convnext_base.clip_laion2b_augreg', 'convnext_base.clip_laion2b_augreg_ft_in1k', 'convnext_base.clip_laion2b_augreg_ft_in12k', 'convnext_base.clip_laion2b_augreg_ft_in12k_in1k', 'convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384', 'convnext_base.clip_laiona', 'convnext_base.clip_laiona_320', 'convnext_base.clip_laiona_augreg_320', 'convnext_base.clip_laiona_augreg_ft_in1k_384', 'convnext_base.fb_in1k', 'convnext_base.fb_in22k', 'convnext_base.fb_in22k_ft_in1k', 'convnext_base.fb_in22k_ft_in1k_384']"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "from models.multiclass_moudle import MulticlassModule\n",
    "from datasets.folder import ImageFolder\n",
    "from datasets.datamodule import DataModule\n",
    "from datasets.transforms import AUGMENTATION_TRANSFORMS, BASIC_TRANSFORMS\n",
    "\n",
    "args = opts().parse(args=[\"--model_name\",\"convnext_base.fb_in22k\"])\n",
    "train_dataset = ImageFolder(\n",
    "    root=\"data/Multiclass\",\n",
    "    transform=AUGMENTATION_TRANSFORMS(\n",
    "        img_size=[224, 224], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    ")\n",
    "datamodule = DataModule(args, train_dataset=train_dataset)\n",
    "model = MulticlassModule(args)\n",
    "\n",
    "# 創建輸入數據\n",
    "import torch\n",
    "from time import time\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "\n",
    "model.eval()\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "summary = ModelSummary(model.eval())\n",
    "print(summary, \"\\n\")\n",
    "\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "model.to(\"cpu\")\n",
    "with torch.no_grad():\n",
    "    start_time = time()\n",
    "    output = model(input_tensor)\n",
    "    cpu_time = time() - start_time\n",
    "print(f\"CPU inference time: {cpu_time:.4f} seconds.\")\n",
    "\n",
    "model.to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    start_time = time()\n",
    "    output = model(input_tensor.cuda())\n",
    "    gpu_time = time() - start_time\n",
    "print(f\"GPU inference time: {gpu_time:.4f} seconds.\")\n",
    "\n",
    "# 計算 CPU 和 GPU 推理時間的差距\n",
    "time_difference_percentage = (cpu_time - gpu_time) / cpu_time * 100\n",
    "print(f\"使用 GPU 比 CPU 快 {time_difference_percentage:.2f}%.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc",
   "language": "python",
   "name": "sc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
